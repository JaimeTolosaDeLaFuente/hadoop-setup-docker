// if not uploaded previously: hdfs dfs -put $DEVDATA/accountdevice /devsh_loudacre/

spark.catalog.listTables("devsh").show

spark.catalog.listColumns("devsh","accounts").show

val accountsDF = spark.read.table("devsh.accounts")
accountsDF.printSchema

val firstLastDF = spark.sql("SELECT first_name,last_name FROM devsh.accounts")
firstLastDF.printSchema
firstLastDF.show(5)

val firstLastDF2 = accountsDF.select("first_name","last_name")
firstLastDF2.printSchema
firstLastDF2.show(5)

val accountDeviceDF = spark.read.option("header","true").option("inferSchema","true").csv("/devsh_loudacre/accountdevice")

accountDeviceDF.createOrReplaceTempView("account_dev")

spark.catalog.listTables("devsh").show

spark.sql("SELECT * FROM account_dev LIMIT 5").show

val nameDevDF = spark.sql("SELECT acct_num, first_name, last_name, account_device_id FROM devsh.accounts JOIN account_dev ON acct_num = account_id")
nameDevDF.show

nameDevDF.write.option("path","/devsh_loudacre/name_dev").saveAsTable("devsh.name_dev")

spark.catalog.listTables("devsh").show
spark.sql("DESCRIBE devsh.name_dev").show

// Confirm new table is in Hive
// $ beeline -u jdbc:hive2://localhost:10000 -e "SHOW TABLES FROM devsh"