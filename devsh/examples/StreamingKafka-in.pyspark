# dfs dfs -put $DEVDATA/devicestatus_stream


# Run with 
# $ pyspark --master local[2]

# Test with 
# $ kafka-topics --create --zookeeper localhost:2181 --partitions 2 --replication-factor 1 --topic status
# $ $DEVSH/scripts/streamtest-kafka.sh status localhost:9092 10 $DEVDATA/devicestatus_stream


kafkaDF = spark.readStream.format("kafka").option("kafka.bootstrap.servers", "localhost:9092").option("subscribe", "status").load()

from pyspark.sql.functions import *
valuesDF = kafkaDF.select(split(kafkaDF.value, ",").alias("status_vals"))

modelTempsDF = valuesDF.select(valuesDF.status_vals[0].alias("model"), valuesDF.status_vals[2].cast("integer").alias("dev_temp")).groupBy("model").avg("dev_temp")

modelTempsQuery = modelTempsDF.writeStream.outputMode("complete").format("console").start()

modelTempsQuery.stop()
