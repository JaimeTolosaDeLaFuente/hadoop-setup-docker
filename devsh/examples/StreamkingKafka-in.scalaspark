// Run with 
// $ spark-shell --master local[2]

// Test with 
// $ kafka-topics --create --zookeeper localhost:2181 --partitions 2 --replication-factor 1 --topic status
// $ $DEVSH/scripts/streamtest-kafka.sh status localhost:9092 10 $DEVDATA/devicestatus_stream

val kafkaDF = spark.readStream.format("kafka").option("kafka.bootstrap.servers", "localhost:9092").option("subscribe", "status").load

val valuesDF = kafkaDF.select(split($"value", ",").alias("status_vals"))

val modelTempsDF = valuesDF.select($"status_vals"(0).alias("model"), $"status_vals"(2).cast("integer").alias("dev_temp")).groupBy("model").avg("dev_temp")

val modelTempsQuery = modelTempsDF.writeStream.outputMode("update").format("console").option("truncate","false").start()

modelTempsQuery.stop


